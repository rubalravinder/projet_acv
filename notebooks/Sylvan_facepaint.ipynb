{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b870ab-abd4-48b0-b0f8-951d141775d5",
   "metadata": {},
   "source": [
    "# Face fill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d9f317-0cc4-43dd-8f86-c17b47ed6529",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb9bb01-cbf2-4db3-a82e-afa62ed3b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import trimesh\n",
    "\n",
    "Holistic = mp.solutions.holistic.Holistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f14a145-cb08-40a5-8794-e268cc966bb2",
   "metadata": {},
   "source": [
    "## Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db003e83-8356-41b1-bb31-a160d2d47510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_filter_with_mediapipe_model(mediapipe_model, mediapipe_based_filter):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    with mediapipe_model as model:\n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                continue  # If loading a video, use 'break' instead of 'continue'.\n",
    "\n",
    "            # Flip the image horizontally for a later selfie-view display, and convert\n",
    "            # the BGR image to RGB.\n",
    "            image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            results = model.process(image)\n",
    "\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            result_image = mediapipe_based_filter(image, results)\n",
    "\n",
    "            cv2.imshow(\"MediaPipe\", result_image)\n",
    "\n",
    "            if cv2.waitKey(5) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b3b788-52cf-4635-9c73-55eb76689763",
   "metadata": {},
   "source": [
    "## Import canonical mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc4c9111-bbc7-49d3-b260-737988983dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"canonical_face_model.obj\",\"r\") as objfile:\n",
    "    scene = trimesh.exchange.obj.load_obj(objfile)\n",
    "triangles = scene[\"faces\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdb414c-87a9-4056-bf9f-a2ecec0e6454",
   "metadata": {},
   "source": [
    "Previous:\n",
    "\n",
    "```python\n",
    "triangles = []\n",
    "with open(\"canonical_face_model.obj\", \"r\") as wavefile:\n",
    "    for line in wavefile:\n",
    "        if line[:1] == \"f\":\n",
    "            triangles.append(\n",
    "                np.array([tup.split(\"/\")[0] for tup in line.split()[1:]], dtype=int) - 1\n",
    "            )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444c49ef-18b7-4c6a-a7f9-0a6054d96cd3",
   "metadata": {},
   "source": [
    "## Pick colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3c623b0-f53d-407a-afcd-07d88bd6f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = [tuple(np.random.choice(range(256), size=3)) for _ in range(30)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eaf5e4-ef62-465f-bcf9-a0a0dbe1a893",
   "metadata": {},
   "source": [
    "## Draw function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef6881-4372-4285-804e-f4161fe44129",
   "metadata": {},
   "source": [
    "Previous:\n",
    "```python\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "def draw_face(image, results, show_face=True):\n",
    "    height, width = image.shape[:2]\n",
    "    if show_face:\n",
    "        if results.face_landmarks:\n",
    "            face_points = np.array([[lm.x, lm.y] for lm in results.face_landmarks.landmark])\n",
    "            tri = Delaunay(face_points)\n",
    "            for i,triangle in enumerate(tri.simplices):\n",
    "                triangle_cnt = face_points[triangle]\n",
    "                triangle_cnt[:,0] *= width\n",
    "                triangle_cnt[:,1] *= height\n",
    "                triangle_cnt = triangle_cnt.astype(int)\n",
    "                cv2.drawContours(image, [triangle_cnt], 0, np.array(color[i%30]).astype(float), -1)\n",
    "\n",
    "    return image\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb400d5b-4ae0-4d07-823c-6bc0a779f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_copy = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "image_copy = None\n",
    "\n",
    "def draw_face(image, results, show_face=True):\n",
    "    global image_copy\n",
    "    height, width = image.shape[:2]\n",
    "    if show_face:\n",
    "        if results.face_landmarks:\n",
    "            face_points = np.array(\n",
    "                [[lm.x, lm.y] for lm in results.face_landmarks.landmark]\n",
    "            )\n",
    "            if image_copy is None:\n",
    "                image_copy = np.zeros_like(image)\n",
    "            image_copy[:, :, :] = image\n",
    "            for i, triangle in enumerate(triangles):\n",
    "                triangle_cnt = face_points[triangle]\n",
    "                triangle_cnt[:, 0] *= width\n",
    "                triangle_cnt[:, 1] *= height\n",
    "                triangle_cnt = triangle_cnt.astype(int)\n",
    "                cv2.drawContours(\n",
    "                    image_copy,\n",
    "                    [triangle_cnt],\n",
    "                    0,\n",
    "                    np.array(color[i % 30]).astype(float),\n",
    "                    -1,\n",
    "                )\n",
    "\n",
    "            alpha = 0.7\n",
    "            image = cv2.addWeighted(image, alpha, image_copy, 1 - alpha, 0)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87529b0-381a-4aab-a1cf-2f43861c49c9",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a10af273-47fb-40d8-8285-ffbd3b1e7731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "run_filter_with_mediapipe_model(\n",
    "    mediapipe_model=Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5),\n",
    "    mediapipe_based_filter=draw_face,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:acv]",
   "language": "python",
   "name": "conda-env-acv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
